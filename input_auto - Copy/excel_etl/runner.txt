# excel_etl/runner.py

from __future__ import annotations

import re
import json
from pathlib import Path
from typing import Callable, Optional, List

import yaml

from .utils.logger import get_logger
from .utils.resources import resource_path
from .utils.io import write_to_template
from .extractors.registry import get_extractor

# IMPORTANT: ensure extractors import/registration happens
# (excel_etl/extractors/__init__.py should import all extractor modules)
from . import extractors as _ensure_registration  # noqa: F401

log = get_logger("runner")


def _load_yaml(relpath: str) -> dict:
    """
    Load a YAML file from the bundled resources (works in dev and PyInstaller).
    """
    return yaml.safe_load(resource_path(relpath).read_text(encoding="utf-8"))


def _choose_extractor(path: Path, routing_cfg: dict) -> Optional[str]:
    """
    Decide which extractor to use for a given input file based on routing rules.
    Current rules support filename_regex; extend as needed.
    """
    fname = path.name
    for rule in routing_cfg.get("routes", []):
        cond = rule.get("when", {})
        ok = True

        # filename regex match (case-insensitive)
        if "filename_regex" in cond:
            ok &= bool(re.match(cond["filename_regex"], fname, flags=re.IGNORECASE))

        # future: add sheet_contains, etc.

        if ok:
            return rule["use_extractor"]

    return routing_cfg.get("default_extractor")


def _gather_input_files(in_dir: Path, exts: List[str]) -> List[Path]:
    """
    Collect files in the input directory matching the given list of extensions.
    """
    files: List[Path] = []
    for ext in exts:
        files.extend(in_dir.glob(f"*{ext}"))
    # sort by name for deterministic order
    return sorted(files, key=lambda p: p.name.lower())


def run_batch(
    input_dir: str,
    out_dir: str,
    template_path: str,
    log_cb: Optional[Callable[[str], None]] = None,
) -> None:
    """
    Process all supported files in input_dir, route each to an extractor,
    write results into the provided Excel template, and save outputs to out_dir.

    Loads bundled configs:
      - config/routing.yaml
      - config/template_map.yaml

    Args:
        input_dir: folder containing raw input files (csv/xls/xlsx/xlsb)
        out_dir: folder to write populated outputs
        template_path: path to the output template .xlsx chosen by the user
        log_cb: optional callback to emit log lines (used by the Tkinter UI)
    """

    def emit(msg: str) -> None:
        if log_cb:
            log_cb(msg)
        else:
            log.info(msg.rstrip("\n"))

    # Load bundled configs
    routing_cfg = _load_yaml("config/routing.yaml")
    template_map = _load_yaml("config/template_map.yaml")

    in_dir = Path(input_dir)
    out = Path(out_dir)
    out.mkdir(parents=True, exist_ok=True)

    # Gather inputs: support CSV, XLS, XLSX, XLSB
    files = _gather_input_files(in_dir, exts=[".csv", ".xls", ".xlsx", ".xlsb"])
    emit(f"Found {len(files)} input files.\n")

    summary = []

    for i, fp in enumerate(files, 1):
        emit(f"[{i}/{len(files)}] {fp.name}\n")
        try:
            # Pick extractor by routing rules
            ex_name = _choose_extractor(fp, routing_cfg)
            if not ex_name:
                emit("  No extractor matched. Skipping.\n")
                summary.append({"file": fp.name, "status": "skipped"})
                continue

            extractor_cls = get_extractor(ex_name)
            extractor = extractor_cls()
            emit(f"  Using extractor: {ex_name}\n")

            # IMPORTANT: pass the file path; extractor reads via readers.read_any()
            result = extractor.extract(fp)

            # Write to the template
            out_file = out / f"{fp.stem}_out.xlsx"
            write_to_template(template_path, template_map, result, out_file)
            emit(f"  Wrote: {out_file.name}\n")

            summary.append({"file": fp.name, "status": "ok", **result})
        except Exception as e:
            emit(f"  ERROR: {e}\n")
            summary.append({"file": fp.name, "status": "error", "error": str(e)})

    # Save a machine-readable run summary
    (out / "summary.json").write_text(json.dumps(summary, indent=2), encoding="utf-8")
    emit("Done.\n")
