def sheet_Discount_rate(ctx: Mapping[str, pd.DataFrame]) -> pd.DataFrame:
    """
    Output sheet: "Discount_rate"

    Steps:
      1) Find cell "Entity" => (RN1, CN1)
      2) On row RN1-1, treat each CGU header (Group/IWPB/CIB/CC) as a span that
         runs until the next header appears.
      3) For each CGU span, on RN1 look for a cell containing "CoE LCY" (case-insensitive).
         That column is the value column for that CGU.
      4) In CN1, find the row for location/entity and read the values.
      5) Return one-row DF: entity, Total, CC, CIB, IWPB (fill 0 when missing).
    """
    import re
    import numpy as np
    import pandas as pd

    dr = ctx["discount_rate"]
    ui = ctx["user_input"]

    # ---- helpers / config ----
    helper_config = {
        "discount_rate": {
            "HBME - United Arab Emirates": "5300_1GRT - HSBC Bank Middle East",
            "Group": "Total",
        }
    }
    # header normalization (case-insensitive)
    cgu_header_map = {"group": "Total", "iwpb": "IWPB", "cib": "CIB", "cc": "CC"}
    wanted_keys = ["Total", "CIB", "IWPB", "CC"]

    # ---- user_input: entity + rollup ----
    if not {"Field", "Value"}.issubset(ui.columns):
        raise KeyError("user_input must have columns ['Field','Value']")
    kv = {str(k).strip(): v for k, v in zip(ui["Field"], ui["Value"])}
    entity_name = str(kv.get("entity", "")).strip()
    rollup_expr = str(kv.get("cgu_rollup", "") or kv.get("cgu_rollups", "")).strip()

    # include both LHS and RHS of '='; normalize via cgu_header_map and dedupe
    def norm(label: str) -> str:
        return cgu_header_map.get(label.strip().lower(), label.strip())

    rollup_targets: list[str]
    if "=" in rollup_expr:
        left, right = rollup_expr.split("=", 1)
        rhs = [x.strip() for x in re.split(r"[+]", right) if x.strip()]
        rollup_targets = [norm(left)] + [norm(x) for x in rhs]
    else:
        rollup_targets = [norm(x) for x in re.split(r"[+]", rollup_expr) if x.strip()]
    # default if parsing empty/failed
    if not rollup_targets:
        rollup_targets = wanted_keys.copy()

    # de-duplicate preserving order, and keep only known keys
    seen = set()
    rollup_targets = [x for x in rollup_targets if not (x in seen or seen.add(x)) and x in wanted_keys]

    # ---- cast to strings for scanning ----
    dr_str = dr.copy().applymap(lambda x: str(x).strip() if pd.notna(x) else "")

    # 1) locate "Entity" (case-insensitive, substring not required here)
    pos = np.argwhere(dr_str.values == "Entity")
    if pos.size == 0:
        pos = np.argwhere(np.vectorize(lambda x: x.lower() == "entity")(dr_str.values))
    if pos.size == 0:
        raise ValueError("Could not find 'Entity' cell")
    RN1, CN1 = pos[0].tolist()

    # 2) build CGU spans from header row RN1-1
    header_row_idx = RN1 - 1
    if header_row_idx < 0:
        raise ValueError("Invalid layout: header row is above the sheet start")

    header_row = dr_str.iloc[header_row_idx, :].tolist()
    starts: list[tuple[int, str]] = []  # (col_index, logical_cgu)
    for j, raw in enumerate(header_row):
        key = raw.strip().lower()
        if key in cgu_header_map:
            starts.append((j, cgu_header_map[key]))
    if not starts:
        raise ValueError("No CGU headers (Group/IWPB/CIB/CC) found on RN1-1")

    # create spans: each header runs until the next header (exclusive)
    max_col = dr_str.shape[1] - 1
    spans: dict[str, range] = {}  # logical -> range(start, end_inclusive+1)
    for idx, (start_col, logical) in enumerate(starts):
        end_col = (starts[idx + 1][0] - 1) if idx + 1 < len(starts) else max_col
        spans[logical] = range(start_col, end_col + 1)

    # restrict to requested rollup targets (but ensure 'Total' is included if present)
    spans = {k: v for k, v in spans.items() if k in set(rollup_targets + ["Total"])}

    # 3) within each span, on RN1, find a column whose cell contains "CoE LCY"
    rn1_row = dr_str.iloc[RN1, :]
    value_cols: dict[str, int] = {}
    for logical, rng in spans.items():
        chosen = None
        for c in rng:
            cell_val = str(rn1_row.iat[c]).strip().lower()
            if "coe lcy" in cell_val:
                chosen = c
                break  # first match in span
        if chosen is not None:
            value_cols[logical] = chosen
        # if not found, we leave it absent for now (will default to 0 later)

    if not value_cols:
        raise ValueError("No 'CoE LCY' columns found (substring search within CGU spans)")

    # 4) find entity row in the 'Entity' column (CN1)
    loc_map = helper_config.get("discount_rate", {})
    # prefer mapped location whose value==entity
    location_label = next((loc for loc, ent in loc_map.items() if ent == entity_name), None)
    # fallback to a known default location if provided
    if location_label is None and "HBME - United Arab Emirates" in loc_map:
        location_label = "HBME - United Arab Emirates"

    entity_col = dr_str.iloc[:, CN1]
    entity_row_idx = None
    if location_label:
        hits = entity_col[entity_col.str.lower() == location_label.lower()].index.tolist()
        if hits:
            entity_row_idx = hits[0]
    if entity_row_idx is None and entity_name:
        hits = entity_col[entity_col.str.lower() == entity_name.lower()].index.tolist()
        if hits:
            entity_row_idx = hits[0]
    if entity_row_idx is None:
        raise ValueError("Could not find the specified location/entity in the Entity column")

    final_entity = loc_map.get(location_label, entity_name) or entity_col.iat[entity_row_idx]

    # 5) fetch values per CGU (default 0 if no CoE LCY found in its span)
    out_vals = {"Total": 0.0, "CC": 0.0, "CIB": 0.0, "IWPB": 0.0}
    for logical in out_vals.keys():
        col_idx = value_cols.get(logical)
        if col_idx is None:
            continue
        raw = dr.iloc[entity_row_idx, col_idx]
        val = 0.0
        try:
            val = float(raw)
        except Exception:
            s = str(raw).strip()
            if s.endswith("%"):
                try:
                    val = float(s[:-1]) / 100.0
                except Exception:
                    val = 0.0
            else:
                try:
                    val = float(s)
                except Exception:
                    val = 0.0
        out_vals[logical] = val

    # assemble one-row output
    return pd.DataFrame([{
        "entity": final_entity,
        "Total": out_vals.get("Total", 0.0),
        "CC": out_vals.get("CC", 0.0),
        "CIB": out_vals.get("CIB", 0.0),
        "IWPB": out_vals.get("IWPB", 0.0),
    }])[["entity", "Total", "CC", "CIB", "IWPB"]]
